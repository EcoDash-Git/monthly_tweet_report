---
title: >
  Twitter Monthly Analysis –
  `r format(params$month_start, '%Y‑%m‑01')` to
  `r format(lubridate::ceiling_date(params$month_start, 'month') - 1, '%Y‑%m‑%d')`
author: ""
date: "`r Sys.Date()`"

params:
  month_start: !r lubridate::floor_date(Sys.Date(), unit = "month")

output:
  html_document:
    toc: true
    toc_float: true
    number_sections: false
  pdf_document:
    latex_engine: xelatex
    toc: true
---



```{r, echo = FALSE,warning = FALSE,message = FALSE}

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

# Libraries
library(tidyverse)
library(lubridate)
library(tidytext)
library(stringi)
library(knitr)
library(kableExtra)
library(forcats)
library(widyr)
library(ggraph)
library(igraph)
library(data.table)
library(sentimentr)
library(DBI)
library(RPostgres)

# Handy labels
month_start <- as.Date(params$month_start)
month_end   <- ceiling_date(month_start, "month") - days(1)
month_label <- format(month_start, "%B %Y")

```

```{r}
# --- Supabase connection (keep as-env in production) ------------------------
Sys.setenv(
  SUPABASE_HOST = "aws-0-us-east-2.pooler.supabase.com",
  SUPABASE_PORT = "6543",
  SUPABASE_DB   = "postgres",
  SUPABASE_USER = "postgres.kubvrwnqmsmhwcuscvje",
  SUPABASE_PWD  = "hfa-tgt8nkj1AVM9vqe"
)

con <- DBI::dbConnect(
  RPostgres::Postgres(),
  host     = Sys.getenv("SUPABASE_HOST"),
  port     = as.integer(Sys.getenv("SUPABASE_PORT")),
  dbname   = Sys.getenv("SUPABASE_DB"),
  user     = Sys.getenv("SUPABASE_USER"),
  password = Sys.getenv("SUPABASE_PWD"),
  sslmode  = "require"
)

twitter_raw2 <- DBI::dbReadTable(con, "twitter_raw")

# ── 1. map handle → canonical user‑id ───────────────────────────
main_ids <- tibble::tribble(
  ~username,            ~main_id,
  "weave_db",           "1206153294680403968",
  "OdyseeTeam",         "1280241715987660801",
  "ardriveapp",         "1293193263579635712",
  "redstone_defi",      "1294053547630362630",
  "everpay_io",         "1334504432973848577",
  "decentlandlabs",     "1352388512788656136",
  "KYVENetwork",        "136377177683878784",
  "onlyarweave",        "1393171138436534272",
  "ar_io_network",      "1468980765211955205",
  "Permaswap",          "1496714415231717380",
  "communitylabs",      "1548502833401516032",
  "usewander",          "1559946771115163651",
  "apus_network",       "1569621659468054528",
  "fwdresearch",        "1573616135651545088",
  "perma_dao",          "1595075970309857280",
  "Copus_io",           "1610731228130312194",
  "basejumpxyz",        "1612781645588742145",
  "AnyoneFDN",          "1626376419268784130",
  "arweaveindia",       "1670147900033343489",
  "useload",            "1734941279379759105",
  "protocolland",       "1737805485326401536",
  "aoTheComputer",      "1750584639385939968",
  "ArweaveOasis",       "1750723327315030016",
  "aox_xyz",            "1751903735318720512",
  "astrousd",           "1761104764899606528",
  "PerplexFi",          "1775862139980226560",
  "autonomous_af",      "1777500373378322432",
  "Liquid_Ops",         "1795772412396507136",
  "ar_aostore",         "1797632049202794496",
  "FusionFiPro",        "1865790600462921728",
  "vela_ventures",      "1869466343000444928",
  "beaconwallet",       "1879152602681585664",
  "VentoSwap",          "1889714966321893376",
  "permawebjournal",    "1901592191065300993",
  "Botega_AF",          "1902521779161292800",
  "samecwilliams",      "409642632",
  "TateBerenbaum",      "801518825690824707",
  "ArweaveEco",         "892752981736779776"
)


# tweets_raw is the data frame you showed
tweets_tagged <- twitter_raw2 %>%
  left_join(main_ids, by = "username") %>%
  mutate(
    # ensure POSIXct (UTC); adapt if your `date` is already POSIXct
    date      = ymd_hms(date, tz = "UTC", quiet = TRUE),
    is_rt_txt = str_detect(text, "^RT @"),
    post_type = case_when(
      is_rt_txt ~ "retweet",
      user_id == main_id & !is_rt_txt & str_detect(text, "https://t.co") ~ "quote",
      user_id == main_id ~ "original",
      TRUE ~ "other"
    )
  )
```



```{r}
# ── Pre‑process master data frame ───────────────────────────────────────────
Sys.setlocale("LC_TIME", "C")   # English weekday names on any platform

df <- tweets_tagged %>% 
  mutate(
    day     = as.Date(date, tz = "UTC"),
    month   = lubridate::month(date),
    year    = lubridate::year(date),
    hour    = lubridate::hour(date),
    weekday = lubridate::wday(date, label = TRUE, abbr = FALSE, week_start = 1)
  ) %>% 
  filter(post_type != "other")

# ── Restrict to the current calendar month ─────────────────────────────────
df_month <- df %>% 
  filter(date >= month_start,
         date <  lubridate::ceiling_date(month_start, "month")) %>% 
  mutate(
    month_day  = lubridate::wday(date, label = TRUE, abbr = FALSE, week_start = 1),
    month_hour = lubridate::hour(date)
  )

if (nrow(df_month) == 0) {
  cat("\n\n### No tweets in", month_label, "– nothing to report.\n\n")
  knitr::knit_exit()
}

```


# Summary Table
```{r}
summary_table <- df_month %>%
  summarise(
    total_tweets    = n(),
    avg_likes       = mean(like_count, na.rm = TRUE),
    avg_comments    = mean(reply_count, na.rm = TRUE),
    avg_impressions = mean(view_count, na.rm = TRUE),
    avg_engagement  = mean(engagement_rate, na.rm = TRUE)
  )

header <- sprintf("Key Twitter Metrics – %s", month_label)

summary_table %>%
  kbl(digits = 1, align = "c") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE, position = "center"
  ) %>%
  row_spec(0, bold = TRUE, color = "white", background = "#000000") %>%
  add_header_above(setNames(5, header))          # ← 5 columns, named “header”



```

# Top Keywords 

```{r}
custom_stopwords <- tibble(word = c("ao","aothecomputer","rt","https","t.co","1","2","3"))
all_stopwords <- bind_rows(stop_words, custom_stopwords)

word_counts <- df_month %>%
  select(text) %>%
  unnest_tokens(word, text) %>%
  anti_join(all_stopwords, by = "word") %>%
  count(word, sort = TRUE) %>%
  slice_max(n, n = 20)

word_counts %>%
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_col() +
  coord_flip() +
  labs(title = "Top 20 Most Common Words in Tweets",
       x = "Word", y = "Frequency") +
  theme_minimal()


```

# TF-IDF by Post Type 

```{r}
word_tfidf <- df_month %>%
  select(post_type, text) %>%
  filter(post_type != "other") %>%
  mutate(
    text = str_remove_all(text, "http\\S+"),
    text = str_remove_all(text, "@\\w+"),
    text = str_remove_all(text, "[[:punct:]]"),
    text = stri_replace_all_regex(text, "[\\p{Emoji_Presentation}\\p{Extended_Pictographic}]+", "")
  ) %>%
  unnest_tokens(word, text) %>%
  filter(!str_detect(word, "^[0-9]+$"), word != "rt") %>%
  anti_join(stop_words, by = "word") %>%
  count(post_type, word, sort = TRUE) %>%
  bind_tf_idf(word, post_type, n) %>%
  group_by(post_type) %>%
  arrange(desc(tf_idf)) %>%
  mutate(rank = row_number()) %>%
  filter(rank <= 10) %>%
  ungroup()

word_tfidf %>%
  mutate(word = reorder_within(word, tf_idf, post_type)) %>%
  ggplot(aes(x = word, y = tf_idf, fill = post_type)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~post_type, scales = "free_y") +
  scale_x_reordered() +
  labs(title = "Top 10 Distinctive Words by Post Type",
       x = "Word", y = "TF-IDF Score") +
  coord_flip() +
  theme_minimal()


```

# Time-Based Analysis 
```{r}

Sys.setlocale("LC_TIME", "en_US.UTF-8")

df_m_daily <- df_month %>%
  mutate(day = as.Date(date, tz = "UTC")) %>%
  count(day, name = "count")

ggplot(df_m_daily, aes(day, count)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  scale_x_date(
    breaks = seq(month_start, month_end, by = "1 week"),
    date_labels = "%a\n%d %b"
  ) +
  labs(title = sprintf("Number of Tweets per Day – %s", month_label),
       x = NULL, y = "Tweet count") +
  theme_minimal()


```




```{r}
hourly_distribution <- df_month %>%
  mutate(hour = hour(date)) %>%
  count(hour) %>%
  mutate(percentage = n / sum(n) * 100)

ggplot(hourly_distribution, aes(x = hour, y = percentage)) +
  geom_col() +
  scale_x_continuous(breaks = 0:23) +
  labs(title = "Tweet Activity by Hour of Day",
       x = "Hour of Day", y = "Percentage of Tweets") +
  theme_minimal()


```





# Engagement Analysis

```{r}
engagement_by_day <- df_month %>%
  group_by(day = as.Date(date)) %>%
  summarise(avg_engagement_rate = mean(engagement_rate, na.rm = TRUE), .groups = "drop")

ggplot(engagement_by_day, aes(x = day, y = avg_engagement_rate)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  labs(title = "Average Engagement Rate Per Day",
       x = "Date", y = "Engagement Rate") +
  theme_minimal()

```


```{r}

engagement_by_day_type <- df_month %>%
  group_by(day = as.Date(date), post_type) %>%
  summarise(avg_engagement_rate = mean(engagement_rate, na.rm = TRUE), .groups = "drop")

ggplot(engagement_by_day_type, aes(x = day, y = avg_engagement_rate, color = post_type)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  labs(title = "Average Engagement Rate Per Day by Post Type",
       x = "Date", y = "Engagement Rate", color = "Post Type") +
  theme_minimal()


```




```{r}
engagement_by_type <- df_month %>%
  group_by(post_type) %>%
  summarise(avg_engagement_rate = mean(engagement_rate, na.rm = TRUE), .groups = "drop")

ggplot(engagement_by_type, aes(x = post_type, y = avg_engagement_rate, fill = post_type)) +
  geom_col() +
  labs(title = "Average Engagement Rate by Post Type",
       x = "Post Type", y = "Average Engagement Rate") +
  theme_minimal() +
  theme(legend.position = "none")


```



# Comments Analysis

```{r}
comments_by_day <- df_month %>%
  group_by(day = as.Date(date)) %>%
  summarise(avg_comments = mean(reply_count, na.rm = TRUE), .groups = "drop")

ggplot(comments_by_day, aes(x = day, y = avg_comments)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  labs(title = "Average Comments (Replies) Per Day",
       x = "Date", y = "Average Comments") +
  theme_minimal()

```


```{r}

comments_by_type <- df_month %>%
  group_by(post_type) %>%
  summarise(avg_comments = mean(reply_count, na.rm = TRUE), .groups = "drop")

ggplot(comments_by_type, aes(x = post_type, y = avg_comments, fill = post_type)) +
  geom_col() +
  labs(title = "Average Comments by Post Type",
       x = "Post Type", y = "Average Comments") +
  theme_minimal() +
  theme(legend.position = "none")

```

```{r}
comments_by_type <- df_month %>%
  group_by(post_type) %>%
  summarise(avg_comments = mean(reply_count, na.rm = TRUE), .groups = "drop")

ggplot(comments_by_type, aes(x = post_type, y = avg_comments, fill = post_type)) +
  geom_col() +
  labs(
    title = "Average Comments by Post Type",
    x = "Post Type",
    y = "Average Comments"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```

# Likes Analysis

```{r}
likes_by_day <- df_month %>%
  group_by(day) %>%
  summarise(avg_likes = mean(like_count, na.rm = TRUE), .groups = "drop")

ggplot(likes_by_day, aes(x = day, y = avg_likes)) +
  geom_line(color = "steelblue", size = 1) +
  geom_point(color = "darkblue", size = 2) +
  labs(
    title = "Average Likes Per Day",
    x = "Date",
    y = "Average Likes"
  ) +
  theme_minimal()
```

```{r}
likes_by_day_type <- df_month %>%
  group_by(day, post_type) %>%
  summarise(avg_likes = mean(like_count, na.rm = TRUE), .groups = "drop")

ggplot(likes_by_day_type, aes(x = day, y = avg_likes, color = post_type)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  labs(
    title = "Average Likes Per Day by Post Type",
    x = "Date",
    y = "Average Likes",
    color = "Post Type"
  ) +
  theme_minimal()
```


```{r}

likes_by_type <- df_month %>%
  group_by(post_type) %>%
  summarise(avg_likes = mean(like_count, na.rm = TRUE), .groups = "drop")

ggplot(likes_by_type, aes(x = post_type, y = avg_likes, fill = post_type)) +
  geom_col() +
  labs(
    title = "Average Likes by Post Type",
    x = "Post Type",
    y = "Average Likes"
  ) +
  theme_minimal() +
  theme(legend.position = "none")


```


# Impressions Analysis

```{r}
views_by_day <- df_month %>%
  group_by(day) %>%
  summarise(avg_views = mean(view_count, na.rm = TRUE), .groups = "drop")

ggplot(views_by_day, aes(x = day, y = avg_views)) +
  geom_line(color = "steelblue", size = 1) +
  geom_point(color = "darkblue", size = 2) +
  labs(
    title = "Average Impressions Per Day",
    x = "Date",
    y = "Average Impressions"
  ) +
  theme_minimal()
```


```{r}
views_by_day_type <- df_month %>%
  group_by(day, post_type) %>%
  summarise(avg_views = mean(view_count, na.rm = TRUE), .groups = "drop")

ggplot(views_by_day_type, aes(x = day, y = avg_views, color = post_type)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  labs(
    title = "Average Impressions Per Day by Post Type",
    x = "Date",
    y = "Average Impressions",
    color = "Post Type"
  ) +
  theme_minimal()
```


```{r}
views_by_type <- df_month %>%
  group_by(post_type) %>%
  summarise(avg_views = mean(view_count, na.rm = TRUE), .groups = "drop")

ggplot(views_by_type, aes(x = post_type, y = avg_views, fill = post_type)) +
  geom_col() +
  labs(
    title = "Average Impressions by Post Type",
    x = "Post Type",
    y = "Average Impressions"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```


# Average Engagement by Day and Hour (Log Scale)

```{r,message=F,warning=F}
# ── Average Engagement by Day & Hour (log‑scale heat‑map) ───────────────────
Sys.setlocale("LC_TIME", "C")          # keep weekday labels in English

df_heatmap <- df_month %>% 
  mutate(
    publish_dt = lubridate::ymd_hms(date, quiet = TRUE),
    day  = lubridate::wday(publish_dt, label = TRUE, week_start = 1),
    hour = lubridate::hour(publish_dt)
  ) %>% 
  group_by(day, hour) %>% 
  summarise(mean_engagement = mean(engagement_rate, na.rm = TRUE), .groups = "drop") %>% 
  mutate(log_engagement = log1p(mean_engagement))

ggplot(df_heatmap, aes(x = hour,
                       y = forcats::fct_rev(day),
                       fill = log_engagement)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c(option = "C", name = "Log Engagement") +
  labs(title = "Average Engagement by Day and Hour",
       x = "Hour of Day", y = "Day of Week") +
  theme_minimal()


```

# Top 10 Best Times to Post – Engagement Rate

```{r}

# ── Top‑10 best times to post (by mean ER) ──────────────────────────────────
top_times <- df_month %>% 
  mutate(
    publish_dt = lubridate::ymd_hms(date, quiet = TRUE),
    day  = lubridate::wday(publish_dt, label = TRUE, week_start = 1),
    hour = lubridate::hour(publish_dt)
  ) %>% 
  group_by(day, hour) %>% 
  summarise(mean_engagement = mean(engagement_rate, na.rm = TRUE), .groups = "drop") %>% 
  arrange(desc(mean_engagement)) %>% 
  slice_head(n = 10)

top_times %>% 
  knitr::kable(
    digits   = 2, align = "c",
    caption  = "Top 10 Best Times to Post – Engagement Rate"
  ) %>% 
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE, position = "center"
  ) %>% 
  kableExtra::column_spec(1:3, width = "5cm") %>% 
  kableExtra::row_spec(0, bold = TRUE, color = "white", background = "#000000")

```


# Engagement by Hour and Post Type

```{r}

heatmap_post_hour <- df_month %>%
  mutate(hour = hour(date)) %>%
  group_by(post_type, hour) %>%
  summarise(mean_eng = median(engagement_rate, na.rm = TRUE), .groups = "drop")

ggplot(heatmap_post_hour, aes(x = hour, y = post_type, fill = mean_eng)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c() +
  labs(title = "Engagement by Hour and Post Type",
       x = "Hour", y = "Post Type", fill = "Median Engagement") +
  theme_minimal()


```



```{r}
# Unigrams correlations vs engagement
tokens <- df_month %>%
  select(tweet_id, text, engagement_rate) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word") %>%
  filter(!str_detect(word, "^\\d+$"), word != "you're")

word_counts <- tokens %>% count(word) %>% filter(n >= 5)
tokens_filtered <- tokens %>% semi_join(word_counts, by = "word")

word_binary <- tokens_filtered %>%
  distinct(tweet_id, word) %>%
  mutate(present = 1) %>%
  pivot_wider(names_from = word, values_from = present, values_fill = 0)

engagement_words <- df_month %>%
  select(tweet_id, engagement_rate) %>%
  inner_join(word_binary, by = "tweet_id")

correlations <- engagement_words %>%
  select(-tweet_id) %>%
  summarise(across(-engagement_rate, ~ cor(.x, engagement_rate, use = "complete.obs"))) %>%
  pivot_longer(everything(), names_to = "word", values_to = "correlation") %>%
  arrange(desc(correlation)) %>%
  filter(!is.na(correlation))

```


# Top 10 Words Most Positively Correlated with Engagement Rate

```{r}

top_pos_words <- correlations %>% filter(word != "you’re") %>% slice_max(correlation, n = 10)
ggplot(top_pos_words, aes(x = reorder(word, correlation), y = correlation)) +
  geom_col() + coord_flip() +
  labs(title = "Top 10 Words Most Positively Correlated with Engagement Rate",
       x = "Word", y = "Correlation") +
  theme_minimal()


```

# Top 10 Words Most Negatively Correlated with Engagement Rate

```{r}
top_neg_words <- correlations %>% slice_min(correlation, n = 10)
ggplot(top_neg_words, aes(x = reorder(word, correlation), y = correlation)) +
  geom_col() + coord_flip() +
  labs(title = "Top 10 Words Most Negatively Correlated with Engagement Rate",
       x = "Word", y = "Correlation") +
  theme_minimal()

```


```{r}
# Bigrams → correlation with engagement
bigrams <- df_month %>%
  select(tweet_id, text, engagement_rate) %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
  filter(!is.na(bigram))

bigrams_separated <- bigrams %>%
  separate(bigram, c("word1","word2"), sep = " ") %>%
  filter(
    !word1 %in% stop_words$word, !word2 %in% stop_words$word,
    !str_detect(word1, "https"), !str_detect(word2, "https")
  ) %>%
  unite(bigram, word1, word2, sep = " ")

bigram_counts <- bigrams_separated %>% count(bigram) %>% filter(n >= 5)
bigrams_filtered <- bigrams_separated %>% semi_join(bigram_counts, by = "bigram")

bigram_binary <- bigrams_filtered %>%
  distinct(tweet_id, bigram) %>%
  mutate(present = 1) %>%
  pivot_wider(names_from = bigram, values_from = present, values_fill = 0)

engagement_bigrams <- df_month %>%
  select(tweet_id, engagement_rate) %>%
  inner_join(bigram_binary, by = "tweet_id")

bigram_correlations <- engagement_bigrams %>%
  select(-tweet_id) %>%
  summarise(across(-engagement_rate, ~ cor(.x, engagement_rate, use = "complete.obs"))) %>%
  pivot_longer(everything(), names_to = "bigram", values_to = "correlation") %>%
  filter(!is.na(correlation)) %>%
  arrange(desc(correlation))



```


# Top 10 Bigrams Most Positively Correlated with Engagement


```{r}
top_positive_bigrams <- bigram_correlations %>% slice_max(correlation, n = 10)
ggplot(top_positive_bigrams, aes(x = reorder(bigram, correlation), y = correlation)) +
  geom_col() + coord_flip() +
  labs(title = "Top 10 Bigrams Most Positively Correlated with Engagement",
       x = "Bigram", y = "Correlation") +
  theme_minimal()


```



# Top 10 Bigrams Most Negatively Correlated with Engagement

```{r}
top_negative_bigrams <- bigram_correlations %>%
  filter(!str_detect(bigram, "^rt\\b")) %>%
  slice_min(correlation, n = 10)

ggplot(top_negative_bigrams, aes(x = reorder(bigram, correlation), y = correlation)) +
  geom_col() + coord_flip() +
  labs(title = "Top 10 Bigrams Most Negatively Correlated with Engagement",
       x = "Bigram", y = "Correlation") +
  theme_minimal()

```




# Top Hashtags by Engagement Rate

```{r}
hashtags <- df_month %>%
  mutate(hashtags = str_extract_all(text, "#\\w+")) %>%
  unnest(hashtags) %>%
  group_by(hashtags) %>%
  summarise(avg_engagement = mean(engagement_rate, na.rm = TRUE), n = n(), .groups = "drop") %>%
  filter(n >= 5) %>%
  arrange(desc(avg_engagement)) %>%
  slice_head(n = 10)

ggplot(hashtags, aes(x = reorder(hashtags, avg_engagement), y = avg_engagement)) +
  geom_col() + coord_flip() +
  labs(title = "Top Hashtags by Engagement Rate",
       x = "Hashtag", y = "Avg Engagement Rate") +
  theme_minimal()


```


# Engagement Rate Distribution by Post Type

```{r}
ggplot(df_month, aes(x = post_type, y = log(engagement_rate), fill = post_type)) +
  geom_boxplot(outlier.color = "red", alpha = 0.7) +
  labs(title = "Engagement Rate Distribution by Post Type",
       x = "Post Type", y = "Log Engagement Rate") +
  theme_minimal() +
  theme(legend.position = "none")


```

# Top 30 Words Most Positively Correlated with Each Other

```{r}
tokens <- df_month %>%
  select(tweet_id, text) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word") %>%
  filter(!str_detect(word, "^\\d+$"), !str_detect(word, "^https"))

common_words <- tokens %>% count(word) %>% filter(n >= 15)
tokens_filtered <- tokens %>% semi_join(common_words, by = "word")

word_correlations <- tokens_filtered %>%
  pairwise_cor(item = word, feature = tweet_id, sort = TRUE)

cleaned_word_pairs <- word_correlations %>%
  mutate(word_a = pmin(item1, item2), word_b = pmax(item1, item2)) %>%
  select(word_a, word_b, correlation) %>%
  distinct() %>%
  arrange(desc(correlation))

cleaned_word_pairs %>%
  filter(correlation > 0.35) %>%
  slice_max(correlation, n = 30) %>%
  knitr::kable(
    digits = 2, align = "c",
    caption = "Top 30 Words Most Positively Correlated with Each Other"
  ) %>%
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE, position = "center"
  ) %>%
  kableExtra::column_spec(1:2, width = "5cm") %>%
  kableExtra::row_spec(0, bold = TRUE, color = "white", background = "#000000")



```


# Top 20 Distinctive Keywords by Engagement Tier

```{r}
df_month <- df_month %>%
  mutate(
    tier = cut(
      engagement_rate,
      breaks = quantile(engagement_rate, c(0, .33, .66, 1), na.rm = TRUE),
      labels = c("Low", "Medium", "High"),
      include.lowest = TRUE
    )
  )

uni <- df_month %>% select(tier, text) %>% unnest_tokens(word, text, token = "words")
bi  <- df_month %>% select(tier, text) %>% unnest_tokens(word, text, token = "ngrams", n = 2) %>%
  separate_rows(word, sep = " ")

tidy_tokens <- bind_rows(uni, bi) %>%
  filter(!word %in% c("https","t.co","rt"), !str_detect(word, "^\\d+$")) %>%
  anti_join(stop_words, by = "word")

tier_keywords <- tidy_tokens %>%
  count(tier, word, sort = TRUE) %>%
  bind_tf_idf(word, tier, n) %>%
  group_by(tier) %>%
  slice_max(tf_idf, n = 20, with_ties = FALSE)

ggplot(tier_keywords, aes(x = reorder_within(word, tf_idf, tier), y = tf_idf, fill = tier)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ tier, scales = "free_y") +
  scale_x_reordered() +
  labs(title = "Top 20 Distinctive Keywords by Engagement Tier",
       subtitle = "Words ranked by TF-IDF score", x = "Keyword", y = "TF-IDF Score") +
  theme_minimal() + coord_flip()

```


# Sentiment Analysis

```{r}
df_month1 <- df_month %>%
  as_tibble() %>%
  mutate(text = str_replace_all(text, "&quot;|&#x2F;", "'"),
         text = str_replace_all(text, "&#x2F;", "/"),
         text = str_replace_all(text, "<a(.*?)>", " "),
         text = str_replace_all(text, "&gt;|&lt;", " "),
         text = str_replace_all(text, "<[^>]*>", " "),
         text = str_replace_all(text, "http.*\\s*", " "),
         text = str_replace_all(text, "\\031", "'"),
         text = str_replace_all(text, "\\[|\\]|\\(|\\)|\\*|~|#|\\n|\\034|\\035|\\tI|_|\\\\", " "),
         text = str_replace_all(text, "\"|'", ""),
         text = str_replace_all(text, "a°|<|>|&amp;|\\024|\\033|U\\+0096", ""),
         words = str_count(text, "\\w+")) %>%
  filter(words > 5)


```



```{r}
polarity_dt   <- lexicon::hash_sentiment_jockers_rinker
sentiment_key <- polarity_dt %>%
  dplyr::filter(!x %in% c("damn","damned","dammit","goddamn","goddamned","hell","hells",
                          "heck","jail","spoiler","goblin","hot","shot","fuck","fucked",
                          "fucks","mindfuck"))
sentiment_key2 <- update_key(polarity_dt, x = data.frame(x = c("hot"), y = c(1)))

```


```{r}
mycomment  <- get_sentences(df_month1$text)
sentiments <- sentiment_by(mycomment, polarity_dt = sentiment_key2)

df_month1 <- df_month1 %>%
  mutate(element_id = seq_len(nrow(df_month1))) %>%
  inner_join(sentiments, by = "element_id")


```


```{r}

# Boxplot of sentiment
df_month1 %>%
  ggplot(aes(x = "", y = ave_sentiment)) +
  geom_boxplot(width = 0.3, outlier.color = "red") +
  labs(title = "Distribution of Average Sentiment Scores",
       y = "Average Sentiment", x = NULL) +
  theme_minimal() + coord_flip()

```


```{r}
# Sentiment class
df_month1 <- df_month1 %>%
  mutate(sentiment = case_when(
    ave_sentiment >  0.05 ~ "positive",
    ave_sentiment < -0.05 ~ "negative",
    TRUE ~ "neutral"
  ))

daily_sentiment <- df_month1 %>%
  group_by(day, sentiment) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(day) %>%
  mutate(percent = count / sum(count) * 100)

ggplot(daily_sentiment, aes(x = day, y = percent, color = sentiment)) +
  geom_line() +
  labs(title = "Daily Sentiment Trend on Twitter",
       x = "Date", y = "Percentage of Tweets", color = "Sentiment") +
  scale_color_manual(values = c("negative" = "red", "neutral" = "gray", "positive" = "blue")) +
  theme_minimal(base_size = 14)

```


```{r}
overall_sentiment <- df_month1 %>%
  count(sentiment) %>%
  mutate(percent = n / sum(n) * 100)

ggplot(overall_sentiment, aes(x = sentiment, y = percent, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  scale_fill_manual(values = c("negative" = "tomato", "neutral" = "khaki", "positive" = "skyblue")) +
  labs(title = "Overall Sentiment Distribution on Twitter",
       x = "Sentiment Type", y = "Percentage of Tweets") +
  theme_minimal(base_size = 14)


```

```{r}
sentiment_by_type <- df_month1 %>%
  count(post_type, sentiment) %>%
  group_by(post_type) %>%
  mutate(percent = n / sum(n) * 100) %>%
  ungroup()

ggplot(sentiment_by_type, aes(x = sentiment, y = percent, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ post_type) +
  scale_fill_manual(values = c("negative" = "tomato", "neutral" = "khaki", "positive" = "skyblue")) +
  labs(title = "Sentiment Distribution by Tweet Type",
       x = "Sentiment Type", y = "Percentage of Tweets") +
  theme_minimal(base_size = 14)



```





```{r}
daily_avg_sentiment <- df_month1 %>%
  group_by(day) %>%
  summarise(avg_sentiment = mean(ave_sentiment, na.rm = TRUE), .groups = "drop")

ggplot(daily_avg_sentiment, aes(x = day, y = avg_sentiment)) +
  geom_line() +
  labs(title = "Average Sentiment Score by Day",
       x = "Date", y = "Average Sentiment") +
  theme_minimal(base_size = 14)

```


```{r}
daily_sentiment_by_type <- df_month1 %>%
  group_by(day, post_type) %>%
  summarise(avg_sentiment = mean(ave_sentiment, na.rm = TRUE), .groups = "drop")

ggplot(daily_sentiment_by_type, aes(x = day, y = avg_sentiment, color = post_type)) +
  geom_line() +
  labs(title = "Average Sentiment Score by Day and Post Type",
       x = "Date", y = "Average Sentiment Score", color = "Post Type") +
  theme_minimal(base_size = 14) + theme(legend.position = "top")


```



```{r}
nrc_key <- lexicon::hash_nrc_emotions %>%
  dplyr::filter(emotion %in% c('trust',"anger","anticipation","fear","sadness","surprise","disgust","joy")) %>%
  dplyr::filter(!token %in% c("damn","damned","dammit","goddamn","goddamned","peach","curse","cursed","hell","hells","heck","fuck","fucked","fucks","mindfuck","punch","money","insane","crazy","shit")) %>%
  dplyr::filter(!(emotion %in% c("fear","sadness") & token == "cringe"))

```


```{r}
emotions2 <- emotion_by(df_month1$text, emotion_dt = nrc_key)
df_month2 <- inner_join(df_month1, emotions2, by = "element_id")


```


```{r}
y <- df_month2 %>%
  pivot_wider(names_from = emotion_type, values_from = ave_emotion) %>%
  mutate(across(c(anger:trust_negated), ~ ifelse(is.na(.x), 0, .x))) %>%
  mutate(
    anger       = anger - anger_negated,
    anticipation= anticipation - anticipation_negated,
    disgust     = disgust - disgust_negated,
    fear        = fear - fear_negated,
    joy         = joy - joy_negated,
    sadness     = sadness - sadness_negated,
    surprise    = surprise - surprise_negated,
    trust       = trust - trust_negated
  ) %>%
  pivot_longer(cols = anger:trust_negated, names_to = "emotion_type", values_to = "ave_emotion")

ggplot(y, aes(x = (ave_sentiment), y = log(engagement_rate))) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, linetype = "dashed") +
  labs(title = "Relationship between Sentiment Polarity and Engagement Rate",
       x = "Average Sentiment Polarity", y = "Log Engagement Rate") +
  theme_minimal(base_size = 14)

```


## Emotion Analysis

```{r}

y_filtered <- y %>%
  filter(!str_detect(emotion_type, "negated$")) %>%
  filter(ave_emotion > 0)

daily_emotion <- y_filtered %>%
  group_by(day, emotion_type) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(day) %>%
  mutate(percent = count / sum(count) * 100)

ggplot(daily_emotion, aes(x = day, y = percent, color = emotion_type)) +
  geom_line(size = 0.5) +
  labs(title = "Daily Emotion Trend",
       x = "Date", y = "Percentage of Tweets", color = "Emotion") +
  theme_minimal(base_size = 14)


```





```{r}
overall_emotion <- y_filtered %>%
  count(emotion_type) %>%
  mutate(percent = n / sum(n) * 100)

ggplot(overall_emotion, aes(x = reorder(emotion_type, percent), y = percent, fill = emotion_type)) +
  geom_col(show.legend = FALSE) + coord_flip() +
  labs(title = "Overall Emotion Distribution",
       x = "Emotion", y = "Percentage of Tweets") +
  theme_minimal(base_size = 14)


```


```{r}
emotion_by_post_type <- y_filtered %>%
  count(post_type, emotion_type) %>%
  group_by(post_type) %>%
  mutate(percent = n / sum(n) * 100) %>%
  ungroup()

ggplot(emotion_by_post_type, aes(x = emotion_type, y = percent, fill = emotion_type)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ post_type) +
  labs(title = "Emotion Distribution by Tweet Type",
       x = "Emotion", y = "Percentage of Tweets") +
  theme_minimal(base_size = 14) + coord_flip()


```


